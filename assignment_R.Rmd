---
title: "Assignment"
author: '10485437'
date: "15/12/2021"
output: 
  html_document:
    code_folding: show
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
To make each chunk of code easy to read, and to isolate code of interest, 
this file has the option to hide and show the different chunks of code at any 
given time. Initially, all code will be on show. To hide code, simply press the
code button to the left of the code chunks. 

# Loading Packages

Firstly, the relevant libraries must be loaded.
```{r, message=FALSE}
library(tidyverse)     
library(afex)           
library(emmeans)        
library(performance)    
library(visdat)        
library(lme4)
library(lmerTest)
library(dplyr)          
library(ggplot2)
library(plotly)         
```
# QUESTION 1

## Loading the dataset

The data must be loaded and visualized.
```{r, message=FALSE}
Visual_data <- read_csv("assignment_dataset_1(1).csv")     

head(Visual_data)     
```
## Data Wrangling

Condition is a factor but is not currently read as factor by R. It therefore 
must be mutated to be read as a factor by R for appropriate analysis. This will
be coded onto a tidied data set. To make the data and analysis easier to read,
condition a is changed to 'visually_normal' and condition b is changed to be
called 'visually_degraded'.
```{r}
tidied_visual_data <- Visual_data %>%        
  mutate(condition = factor(condition)) %>%
  mutate(condition = recode(condition,
                            "condition_a" = "Visually_normal",
                            "condition_b" = "Visually_degraded"))
head(tidied_visual_data)
```
## Producing Descriptive Statistics

It is appropriate to generate descriptive statistics (mean and standard 
deviation of each condition) and plots to visualize the data. This will provide 
a preliminary idea of the effect the anova may find.
```{r}
tidied_visual_data %>%
  group_by(condition) %>%  
  summarise(mean_response_time = mean(response_time),
            sd_response_time = sd(response_time))
```
Condition A (Normal visual quality) seems to have a faster response time, and 
therefore be pronounced at a faster rate than condition B (visually degraded 
words). However, there is overlap in the standard deviations. To see the 
relationship more clearly, a plot could help to visualize the potential effect 
in the data. 
```{r}
tidied_visual_data %>%
  mutate(condition = str_to_title(condition)) %>%
  ggplot(aes(x = condition, y = response_time, colour = condition)) +
  geom_violin() +                   
  geom_jitter(width = .1, alpha = .5) +
  stat_summary(fun.data = "mean_cl_boot", colour = "black") +
  guides(colour = FALSE) +
  labs(x = "Visual Quality",
       y = "Time taken to Pronounce Word (ms.)",
       title = "Time Taken to Pronounce Words Presented in Different Visual 
                                           Qualities",
       caption = "Figure 1: Words of a visually degraded presentation appear to 
       induce slower pronunication times than normal visual 
       presentations of the same word") +
  theme_minimal()
```

The graph indicates that the visually degraded words are pronounced slightly 
slower than the normal visual quality words. This difference must be tested for
significance with an ANOVA.

## Conducting an ANOVA

To run an ANOVA, a model of the data must be produced for a between participant 
design.
```{r}
visual_model <- aov_4(response_time ~ condition + (1 | participant), 
                      data = tidied_visual_data)
```
### Interpretting the Model Output 

The summary() function can provide the output of the ANOVA from the visual_model
```{r}
summary(visual_model)
```
## Results and Interpretation

A one way independent ANOVA was conducted to investigate the influence of the 
visual quality of a word representation, on how an quickly an individual can 
pronounce the word. The ANOVA revealed a significant effect of visual quality 
(F(1, 94) = 15.83, p = 0.0001, ηG2 = 0.144). Pairwise analysis is not needed as
the investigation only has two variables. Thus, the descriptive statistics
reveal the significant effect to be driven by visual normal words being 
pronounced at a faster rate than visually degraded words (1002 ms. vs. 1020 ms) 
agreeing with the initial hypothesis. 

# Question 2

## Loading data 

Firstly, the data must be loaded and visualized. 
```{r message=FALSE}
caffeine_data <- read_csv("assignment_dataset_2(1).csv")  

head(caffeine_data)                   
```
From looking at the first 6 rows of data, it is clear that the condition (visual
quality) is not being viewed as factors by R. This must be changed with some 
data wrangling. 

## Data wrangling 

Using the mutate function, condition can be changed to be viewed as a factor
in R. This will be coded onto a tidied data set. We can then visualise the data 
to see the new data set.
```{r}
tidied_caffeine_data <- caffeine_data %>%   
  mutate(condition = factor(condition)) %>%
    mutate(condition = recode(condition,
                            "condition_a" = "Visually_normal",
                            "condition_b" = "Visually_degraded")) %>%
  rename(Caffeine = caffeine, Response_Time = response_time, 
         Condition = condition)


head(tidied_caffeine_data)                   
```
## Generating descriptive statistics

Now to generate descriptive statistics i.e. mean and standard deviation. The 
first chunk of code will present the individual mean response times of the 
different coffee intakes in visually normal and degraded conditions. The second
chunk highlights the mean response time despite caffeine intake for under each
condition.
```{r}
tidied_caffeine_data %>%
  group_by(Condition, Caffeine) %>% 
  summarise(Mean_Response_Time = mean(Response_Time),
            sd_Response_Time = sd(Response_Time))
```
```{r}
tidied_caffeine_data %>%
  group_by(Condition) %>% 
  summarise(Mean_Response_Time = mean(Response_Time),
            sd_Response_Time = sd(Response_Time))
```
Now the data has been further tidied, it can be presented in a figure to 
visualise potential relationships. Hovering the cursor over each data point will
present the parameters of that data point, including caffeine consumption, 
response time and visual quality of word presentation (represented as 
Condition). Clicking on either visual quality variable within the legend will 
remove it from the graph - this isolates a view of the response time in one 
visual quality condition when taking into account caffeine consumption e.g. only
looking at response time to visually degraded words when taking caffeine 
consumption into account. Re-clicking the variable will return it to view.
```{r}
graph2 <- tidied_caffeine_data %>%
  ggplot(aes(x = Caffeine, y = Response_Time)) +
  geom_point(aes(colour = Condition), size = 3, shape = 10, alpha = .4) +
  theme(text = element_text(size = 14)) +
  theme_minimal() +
  theme(legend.position="bottom") +
  labs(x = "Caffeine Consumption",
       y = "Response Time (ms.)", 
       colour = "Condition",
       title = "Response Time to pronunciate words of different Visual Quality
              whilst considering caffeine consumption")

ggplotly(graph2)
```
Condition A participants (visually normal presentations) are clustered within 
the lower caffeine consumption with lower response times. This contrasts with 
the condition b participants (visually degraded presentations) who are clustered 
within higher caffeine consumption and higher response times (slower responses).
If there is a relationship between caffeine consumption and response time, it is
not clear from this visualisation - the data points do not follow a clear path. 
An ANCOVA is needed to confirm this finding.

## Building models for ANCOVA

Firstly, we can use the model built in question1 to model the effect of 
condition on response time (the visual_model). We know from question 1 that this
has a significant F value and minuscule P value. Visually degraded presentations
appear to be pronounced at a slower rate than words presented with normal 
visual quality.

We then build an ANCOVA model with the co-variate of caffeine consumption. The
factorize parameter is set to FALSE so that caffeine is not treated as an
experimental factor but as a continuous predictor.
```{r}
caffeine_model <- aov_4(Response_Time ~ Caffeine + Condition + (1 | participant)
                        , data = tidied_caffeine_data, factorize = FALSE)

anova(caffeine_model)
```
This output suggests there is not a significant effect of condition (visual
quality of word presentation) (F(1,93) = 3.57, p = 0.06) or of caffeine 
(F(1,93) = 1.1366, p = 0.29). As condition is no longer significant when 
caffeine is considered, we cannot conclude that visual quality alone has a 
significant effect on pronunciation time of words.

Although there was no significant effect found, it is good to run further pair-
wise analysis as this function provides the adjusted means as produced by R.
This allows comparison of the output of the ANCOVA to other models such as a
linear model.
```{r}
emmeans(caffeine_model, pairwise ~ Caffeine * Condition, adjust = "none")
```
## Question 2b: Producing a linear regression model of the data for comparison

First we must check how the conditions are coded in terms of their contrasts.
```{r}
contrasts(tidied_caffeine_data$Condition)
```
Now the contrasts are correctly coded, a linear model can be produced for the 
ANCOVA. 

## Building ANCOVA as linear regression model

We then build an ANCOVA linear regression model using the lm function, 
accounting for caffeine (our covariate). This is to compare the results of the 
ANCOVA conducted in question 2 with a linear model.
```{r}
caffeine_model_ancova <- lm(Response_Time ~ Caffeine + Condition, 
                            data = tidied_caffeine_data)
caffeine_model_ancova
```
Caffeine has not been coded as a factor, so to use this output for our equation
we must calculate the mean caffeine intake. 
```{r}
mean(tidied_caffeine_data$Caffeine)
```
Now caffeine has been accounted for, it can be added into the equation alongside
the other values produced by this ANCOVA linear model:

Response Time = Intercept + β1(caffeine) + β2(visually degraded)
Response Time = 998.547 + 2.489(2.55) + 12.783(0)
Response Time = 1004.89 ms

This is the same response time as produced by the adjusted means of the ANCOVA,
(when rounded up) 

Response Time = Intercept + β1(caffeine) + β2(visually degraded)
Response Time = 998.547 + 2.489(2.55) + 14.989(1)
Response Time = 1019.88

This is nearly identical to the adjusted mean as provided by the ANCOVA.

Ultimately, both the linear and ANCOVA model produced nearly identical results
in estimating the mean response times of word pronunciation when changing the 
visual quality of word presentation. Both models are sufficient to conduct the
analysis. Further analysis could produce a linear model for question 1, which 
following the results of this analysis would show the same results of the ANOVA. 
This would confirm our finding that linear models can find the same results as 
ANOVAs and ANCOVAs.

# Question 3

## Loading data

Firstly, the data needs to be loaded and visualized using the head function.
```{r}
priming_data <- read.csv("assignment_dataset_3(1).csv")

head(priming_data)
```
The conditions are not being read as factors by R, this needs to be changed.

## Data Wrangling 

R must read the data in a long format for our analysis, it is currently in a 
wide format. The data can be reshaped using the pivot_longer() function. The 
condition column must then be separated into "Prime" and "Target"- this will 
enable us to carry out the experimental 2x2 repeated measures design. Prime and 
Target must be changed to be read as factors by R.
```{r}
longer_priming_data <- priming_data %>%
  pivot_longer(cols = c(positiveprime_positivetarget, 
                        positiveprime_negativetarget, 
                        negativeprime_positivetarget, 
                        negativeprime_negativetarget), 
               names_to = "Condition", 
               values_to = "RT")

tidied_priming_data <- longer_priming_data %>% 
  mutate(Condition = recode(Condition,
                            "1" = "positiveprime_positivetarget",
                            "2" = "positiveprime_negativetarget", 
                            "3" = "negativeprime_positivetarget", 
                            "4" = "negativeprime_positivetarget")) %>%
  separate(col = "Condition", into = c("Prime", "Target"), sep = "_") %>%
  mutate(Prime = factor(Prime), Target = factor(Target))

head(tidied_priming_data)
```

## Producing descriptive statistics

Now to produce descriptive statistics to picture the possible effect in the 
data.
```{r}
tidied_priming_data %>%
  group_by(Prime, Target) %>%
  summarise(mean_RT = mean(RT), sd_RT = sd(RT))
```

It appears that the participants respond faster to positive and negative
images following a prime of the same valence. 

A graph will present this trend in a more clearer picture. 
```{r}
tidied_priming_data %>%
  ggplot(aes(x = Prime:Target, y = RT, colour = Prime:Target)) +
  geom_violin() +
  geom_jitter(width = .1, alpha = .25) +
  guides(colour = FALSE) +
  stat_summary(fun.data = "mean_cl_boot", colour = "black") +
  theme_minimal() +
  theme(text = element_text(size = 10)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust = .5)) +
  labs(x = "Prime X Target", y = "RT (ms)", 
  title = "Response time to Target images when Prime images are of the same or 
                                              different Valence")
```

An ANOVA will demonstrate the true relationships within the data. 

## Conducting ANOVA

Now to build our ANOVA model for the 2x2 repeated measures design, and run an
ANOVA.
```{r}
prime_model <- aov_4(RT ~ Prime * Target + (1 + Prime * Target | participant), 
                     data = tidied_priming_data, na.rm = TRUE)

anova(prime_model)
```

The main effects of Prime (F(1,147) = 0.31, p = 0.58) and Target 
(F(1,147) = 0.24, p = 0.63) are not significant. However, the interaction 
between the target and prime format is significant (F(1,147) = 17.18, p < .001).
Therefore, conducting pairwise comparisons will identify what condition drives
the significant interaction effect. 
```{r}
emmeans(prime_model, pairwise ~ Prime * Target, adjust = "none")
```
The pairwise comparisons demonstrate that the response time of a participant
is much faster when the prime and the target are of the same valence, relative
to when the prime and target are of different valence. For instance, 
participants responded faster to a positive target following a positive prime, 
relative to a negative prime (t(147) = 2.906, p = .0042). Similarly, 
participants responded faster to a negative target following a negative prime, 
relative to a positive prime (t(147) = 3.132, p = .0021). 

Therefore, on their own a negative priming image could not elicit a faster 
response relative to a positive priming image succeeded by a neutral image. 
However, when the target image is of the same valence as the prime image, a 
significant interaction effect occurs such that it will elicit a faster response
time from participants. 

# Binder

Binder is a tool that allows anyone to view your data, code and computational
environment from their device (phone, desktop, laptop). This is key for 
reproducibility because updated versions of R can change code for a function
such that the old code no longer works. The binder URL allows the user to open
the R version that the code was originally built in.

Please find the binder URL for this code and data below:

https://mybinder.org/v2/gh/greeves23/Assignment.git/HEAD?urlpath=rstudio 